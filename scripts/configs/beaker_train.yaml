version: v2
description: herm-train
tasks:
  - name: herm-train
    image:
      beaker: jacobm/herm_train_test_final_maybe
    command: [
      '/bin/sh', '-c'
    ]
  arguments: ['SCRIPT_HERE']
    envVars:
      - name: CUDA_DEVICE_ORDER
        value: PCI_BUS_ID
      - name: TRANSFORMERS_CACHE
        value: ./cache/
      - name: WANDB_PROJECT
        value: open-instruct
      - name: WANDB_WATCH
        value: false
      - name: WANDB_LOG_MODEL
        value: false
      - name: WANDB_DISABLED
        value: true
    datasets:
      - mountPath: /data
        source:
          beaker: Yizhongw03/processed_open_instruct_data
      - mountPath: /mmlu
        source:
          beaker: Yizhongw03/mmlu
      - mountPath: /hf_llama_models
        source:
          beaker: Yizhongw03/hf_llama_model_7B
    result:
      path: /output
    resources:
      gpuCount: 4
    context:
      cluster: ai2/allennlp-cirrascale
      priority: high